\chapter{Comparison to other formulations of the literature}

In this chapter, the proposed formulation (BBA) is compared to other five formulations of the recent literature besides its immediate predecessor (FMT).
A concise review of these other formulation is given in~\cref{sec:other_formulations}.
Differently from BBA and FMT, the employed implementation of these formulations was written in C++, for the CPLEX solver, and not by the author of this thesis.
To control differences between the implementations, the design of the experiments is different from the other chapters: the implementations are used only to generate and save the models into files (not to solve the models), and both CPLEX and Gurobi are called from the commandline to solve each of these saved models.
To shade no doubt over the specific experiment setup and design, it is exhaustively described in~\cref{sec:setup_other_formulations} and~\cref{sec:outine_experiments_other_formulations}.
Besides the comparison between the formulations in~\cref{sec:results_comparing_other_formulations}, a comparison between solvers is also presented (\cref{sec:results_comparing_solvers}) which allow us to dispel any doubts about the choice of solver favoring one formulation over another.

\section{Concise review of the newly considered formulations}
\label{sec:other_formulations}

For the sake of explanation, the author chose to aggregate some of the formulations in the same paragraph when they share similar modeling strategies.
The author seeks to highlight how the interpretation of solutions can lead to very different formulations.

\emph{The {\modelBCE} formulation}, proposed for the Guillotine Strip Packing Problem in~\citet{messaoud:2008} and adapted for the {\myproblem} in~\citet{martin:2020}, is based on a theorem that characterizes guillotine patterns and uses coordinates at which items may be located.
The theorem states that a pattern is of guillotine-type, if and only if, for any region (i.e., sub-rectangle) of the object, at least one of the following conditions is satisfied:
(i) this region contains only a single item;
(ii) the segments of the items length in this region on the x-axis consist of at least two disjoint intervals; and,
(iii) the segments of the items width in this region on the y-axis consist of at least two disjoint intervals.
The formulation is compact in the numbers of variables and constraints with \(O(n^4)\) for the GSPP, where $n$ is the number of items to be packed.
This formulation seems to recall the interval-graph approach of \citet{fekete:1997} for the non-guillotine Orthogonal Packing Problem.

\emph{The {\modelGrid} formulation}, proposed in~\citet{martin:2020}, assumes that each solution can be represented by a sequence of horizontal and vertical guillotine cuts over a two-dimensional grid interpretation of object $L \times W$.
It was inspired by a formulation for the non-guillotine version of the {\myproblem} from~\citet{beasley:1985:nonguillotine}.
In a {\modelGrid} model, a binary variable $x_{kij}$ represents the allocation of the left-bottom corner of an item type $k \in \{1,\ldots,m\}$ to a point $(i,j)$ on the object, $0 \leq i \leq L-l_k$, $0 \leq j \leq W-w_k$.
Taking into consideration the constraints from~\citet{beasley:1985:nonguillotine}, it ensures a constrained pattern and avoids the overlap between any pair of allocated/cut items, which is related to a maximum clique problem.
Then it satisfies the guillotine cutting with binary variables for horizontal cuts $h_{ii'j}$, $0 \leq i < i' \leq L$, $0 \leq j \leq W$, vertical cuts $v_{ijj'}$, $0 \leq i \leq L$, $0 \leq j < j' \leq W$, and enabled rectangles $p_{i_1 i_2 j_1 j_2}$, $0 \leq i_1 < i_2 \leq L$, $0 \leq j_1 < j_2 \leq W$.
The main concepts involve associating: 
(i) the variables $x_{kij}$, $h_{ijj'}$ and $v_{ii'j}$ by prohibiting horizontal and vertical cuts on allocated items and imposing the allocation of the items on cut corners; 
(ii) the variables $h_{ii'j}$, $v_{ijj'}$ and $p_{i_1 i_2 j_1 j_2}$ by allowing only horizontal and vertical edge-to-edge cuts in enabled rectangles.
The formulation is pseudo-polynomial in the numbers of variables and constraints with \(O(mLW+L^2W^2)\).
As expected, one can reduce the number of variables and constraints by using the discretization of normal sets or related ones \citet{herz:1972,cw:1977}.
%Part of these modeling strategies was explored in the context of an object with several defects in~\cite{martin:2020:ijpr,martin:2021:ijpr}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Martin et al. (2020) - bottom-up and top-down
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\emph{The {\modelHierarchical} and {\modelImplicit} formulations}, proposed in~\citet{martin:2020:bottom}, are inspired in the bottom-up strategy of successive horizontal and vertical builds of the items.
A build envelops two small rectangles to generate a larger rectangle.
For instance, as introduced in~\citet{wang:1983}, the horizontal build of items $l_1 \times w_1$ and $l_2 \times w_2$ provides a larger rectangle of size $(l_1+l_2)\times \max\{w_1;w_2\}$, and the vertical build provides a larger rectangle of size $\max\{l_1;l_2\} \times (w_1+w_2)$.
Defining an {\modelHierarchical} or {\modelImplicit} model, it requires to previously determine an upper bound $\bar{n}$ to the maximum number of builds on object $L \times W$ (e.g., $\bar{n}=\sum_{i \in I} b_i$).
The {\modelHierarchical} formulation is pseudo-polynomial as its definition requires an explicit binary tree structure, which is generated by a procedure that considers upper bound $\bar{n}$ as an input.
This binary tree structure is represented by a set of triplets $(j,j^-,j^+)$, where $j^-$ and $j^+$ are the left and right child nodes of node $j$, respectively; the root node $j=1$ represents the object (i.e., the solution).
Its main concepts involve ensuring:
(i) each node $j$ of the binary tree structure can represent either a copy of an item type $i \in I$ (binary variable $z_{ji}$), a horizontal build (binary variable $x_{jh}$), a vertical build (variable $x_{jv}$), or it is not necessary in the solution; 
(ii) the solution represents a guillotine pattern (i.e., a virtual binary tree) by linking the variables $x_{jo}$, $o \in \{h,v\}$, of each parent node $j$ with the variables of its child nodes $j^-$ and $j^+$; and,
(iii) the variables $L_j$ and $W_j$ are considered to represent, respectively, the length and width of a node $j$ according to the previous definition of horizontal and vertical builds, over variables $z_{ji}$ and $x_{jo}$.
The {\modelImplicit} formulation, however, is compact as it considers the set of binary variables $y_{jk}$, $j,k \in \{1,\ldots,\bar{n}-1\}$, $j<k$, for representing implicitly the binary tree structure.
The {\modelHierarchical} and {\modelImplicit} formulations were first proposed as integer non-linear programs, and then they were linearized through the use of disjunctive inequalities of big-M type.

\emph{The {\modelOrigami} formulation}, proposed in~\citet{martin:2020:top}, is inspired in the top-down strategy of successive cuts on the original and residual objects towards the items.
It makes use of the binary tree structure initially proposed for the {\modelHierarchical} formulation.
As a consequence, it presumes the same constraints for representing a guillotine pattern (i.e., a virtual binary tree) by linking the variables $x_{jo}$, $o \in \{h,v\}$, of each parent node $j$ with the variables of its child nodes $j^-$ and $j^+$.
However, its geometric constraints are non-trivial.
Since variables $L_j$ and $W_j$ are no longer in the formulation, the sizes of the residual objects (i.e., nodes of the binary tree structure) are defined according to the decisions taken in the previous residual objects.
Alternatively stated, the decisions of each node $j$ take into consideration the previous decisions of all its ancestral nodes up to the root node $n=1$ through disjunctive inequalities of big-M type.

\section{Experiments setup}
\label{sec:setup_other_formulations}

Every experiment in this section used the following setup.
The CPU was an AMD\textsuperscript{\textregistered} Ryzen\textsuperscript{TM} 9 3900X
 12-Core Processor %(3.8GHz, cache: L1 -- 768KiB, L2 -- 6 MiB, L3 -- 64 MiB)
and 32GiB of RAM were available. %(2 x Crucial Ballistix Sport Red DDR4 16GB 2.4GHz)
The operating system used was Ubuntu 20.04 LTS (Linux 5.4.0).
Two kernel parameters had non-default values: \texttt{overcommit\_memory = 2} and \texttt{overcommit\_ratio = 95}.
Hyper-Threading was disabled.
Each run executed on a single thread, and no runs executed simultaneously.
The computer did not run any other CPU bound task during the experiments.

The models for the {\modelBecker} and {\modelFMT} formulations were built using the Julia language and the Gurobi solver.
The models for the {\modelBCE}, {\modelGrid}, {\modelHierarchical}, {\modelImplicit}, and {\modelOrigami} formulations were built using C++ and the CPLEX solver.
To homogeinize the experiments, these implementations were used only to built the models and then save them to MPS files.
Each selected combination of formulation, rotation configuration, and instance originated a single MPS file.
A Julia script then executed each MPS file in four different configurations: CPLEX/LP, CPLEX/MIP, Gurobi/LP, and Gurobi/MIP.

The implementation of {\modelBecker} and {\modelFMT} formulations is available at an online repository\footnote{See~\url{https://github.com/henriquebecker91/GuillotineModels.jl/tree/0.5.0}}.
The scripts for (i) saving the {\modelBecker} and {\modelFMT} models as MPS and (ii) solving all MPS files are also availables\footnote{See~\url{https://github.com/henriquebecker91/phd/tree/BMC-1}}.
The implementations of all the other formulations, as well as the script for generating the MPS files, are available upon request to Martin Pereira Martin\footnote{The ORCID of Martin Pereira Martin is \href{https://orcid.org/0000-0002-6722-7571}{0000-0002-6722-7571}, and he is the main author of \citet{martin:2020}, \citet{martin:2020:bottom}, and \citet{martin:2020:top}.} who graciously let the author borrow his implementations for the purpose of this comparison. %at~\url{https://github.com/mateuspmartin/g2slopp/tree/BMC-1} (CHECK WITH MARTIN IF WE ARE GONNA UN-PRIVATE IT NOW).
The same version of the compilers and solvers was used for the MPS generation and the MPS solving phases.
Those are: Julia 1.5.3, g++ 9.3.0, CPLEX 20.1, and Gurobi 9.1.1.
At least for the solvers, these were the latest versions available.

In both CPLEX and Gurobi some non-default configurations were used.
The solvers were configured to:
employ a single thread;
use a specified seed (\texttt{CPX\_PARAM\_RANDOMSEED}, in CPLEX, and \texttt{Seed}, in Gurobi, were set to one);
employ an integer tolerance adequate for the instances; avoid finishing with suboptimal solutions for the selected datasets (\texttt{CPX\_PARAM\_EPGAP}, in CPLEX, and \texttt{MIPGap}, in Gurobi, were set to \(10^{-6}\));
and respect an one hour time-limit (\texttt{CPX\_PARAM\_TILIM}, in CPLEX, and \texttt{TimeLimit}, in Gurobi, were set to 3600). For a more graceful handling of memory exhaustion, we also set CPLEX parameter \texttt{CPXPARAM\_MIP\_Limits\_TreeMemory} to 28672 (Gurobi does not seem to provide a similar parameter).
Only when solving the {\modelFMT} and {\modelBecker} formulations, we use the barrier method for solving the LP and for solving the root node relaxation (\texttt{CPXPARAM\_LPMethod} and \texttt{CPXPARAM\_MIP\_Strategy\_StartAlgorithm}, in CPLEX, were both set to 4, and \texttt{Method}, in Gurobi, was set to 2).

\section{Outline of the experiments}
\label{sec:outine_experiments_other_formulations}

A short description of the instance datasets used in this section follows.
More details about each dataset can be found in the Appendix.

\begin{description}
	\item [CU/CW] Datasets introduced by~\citet{fayard:1998}. Their names stand for Constrained (demand) and Unweighted/Weighted. They totalize 22 instances: CU1--11 and CW1--11.
	% APT: 10.1016/S0305-0548(00)00095-2
	\item [APT] Dataset introduced by~\citet{alvarez:2002:tabu}. The whole dataset consists of 40 instances (APT10--49), however, only the second half (APT30--49) is employed here, because the first half is for the unconstrained demand variant. The APT30--39 are unweighted and APT40--49 are weighted.
	\item [FMT59] Group of instances assembled by~\cite{furini:2016} with instance subsets from previous datasets. Already employed in previous chapters.
	\item [Easy18] A subset of FMT59 we defined for this section. Its purpose is to reduce the number of runs needed before we discard a formulation from further consideration. The dataset contains: cgcut1--3, gcut1--12, OF1--2, and wang20.
\end{description}

The author selected these datasets because they were already employed by the prior work.
For the CU, CW, and APT datasets, with and without rotation, we use the best known lower bounds from~\citet{velasco:2019}.
For the FMT59 dataset, without rotation, \citet{furini:2016} presents every optimal value\footnote{There is only one typo: the optimal value of the okp2 instance is 22502, not 22503.}, but there is no comprehensive source on the best known values for this dataset when rotation is allowed.

Each run can be uniquely identified by a combination of instance, formulation, rotation configuration (allow rotation or not), solve mode (MIP or LP), and solver (CPLEX or Gurobi).
The first three characteristics determine a MPS file, the last two determine four distinct runs over the same MPS file.

The whole set of runs consists of:
\begin{enumerate}
\item The Easy18 instances combined with each of the seven considered formulations and both rotation configurations, except by the BCE formulation with rotation enabled, which we did not implement.
\item The CU, CW, and FMT59 instances combined with the {\modelBecker}, {\modelOrigami}, hierachical, and {\modelImplicit} formulations and both rotation configurations.
\item The APT instances combined with the four formulations mentioned above but only with rotation disabled. There were no successful runs with rotation disabled and, therefore, we decided to not spend computational effort in the rotation enabled counterparts. % TODO: check with Martin if we should run the rotation ones for APT.
\end{enumerate}

\section{Comparison between solvers}
\label{sec:results_comparing_solvers}

The goal of this section is to answer two questions:
(i) is one of the solvers superior in our context?
(ii) does a choice of solver benefit a specific formulation?

\Cref{tab:cplex_vs_gurobi} answers the first question by revealing a small but consistent advantage for the Gurobi solver.
Nevertheless, Gurobi does not completely dominates CPLEX, as each solver had some instances only solved by it.

\begin{table}[h]
  \center
  \caption{Comparison amongst CPLEX and Gurobi results.}
  \setlength\doublerulesep{0.05\baselineskip}
  \begin{tabular}{lcrrrrrr}
    \hline\hline
    \textbf{Solver} & \textbf{Type} & \textbf{\#opt} & \textbf{\#u. opt} & \textbf{\#best} & \textbf{\#c. best} & \textbf{avg. time} & \textbf{avg. s. time} \\\cmidrule(lr){1-2}\cmidrule(lr){3-8}
     CPLEX & MIP & 288 & 12 &  96 & 16 & 2435.86 & 455.21 \\
    Gurobi & MIP & 302 & 26 & 218 & 63 & 2339.84 & 353.62 \\
     CPLEX & LP  & 704 &  4 & 194 &  6 &  379.17 &  40.62 \\
    Gurobi & LP  & 720 & 20 & 530 & 24 &  297.79 &  31.78 \\\hline\hline
  \end{tabular}
  \legend{
The meaning of each column follow:
\emph{\#opt} -- number of runs finished by optimality;
\emph{\#u. opt} -- number of optimal runs unique to the respective solver (i.e., other solver did not reach optimality);
\emph{\#best} -- number of optimal runs in which the respective solver finished before the other solver (counting the ones not finished by the other solver);
\emph{\#c. best} -- number of clean best times, i.e., optimal runs that took at least one minute for the respective solver and either were not solved by the other solver or it took double the time to solve;
\emph{avg. t.} -- mean run time in seconds (runs ended by timeout or memory exhaustion are counted as taking one hour);
\emph{avg. o. t.} -- mean run time of optimal runs in seconds.
  }
  \label{tab:cplex_vs_gurobi}
\end{table}

\begin{table}[h]
  \center
  \caption{Comparison amongst CPLEX and Gurobi results by formulation.}
  \setlength\doublerulesep{0.05\baselineskip}
  \begin{tabular}{lrrrrrrr}
    \hline\hline
    \textbf{Measure} & \textbf{\modelBCE} & \textbf{\modelBecker} & \textbf{\modelFMT} & \textbf{\modelGrid} & \textbf{\modelHierarchical} & \textbf{\modelImplicit} & \textbf{\modelOrigami} \\\hline
    Optimal & 105.88 &  99.31 & 131.57 & 150.00 & 100.00 & 100.00 & 101.24 \\
    T. Time &  85.45 & 101.75 &  74.71 &  58.61 &  45.09 &  27.68 &  67.60 \\\hline\hline
  \end{tabular}
  \legend{Percentage of solved runs and total time spent by Gurobi in relation to CPLEX, broken down by formulation, for all MILP runs. Runs ended by time or memory limit are counted as taking one hour. Source: the author.}
  \label{tab:percentages_gurobi_cplex}
\end{table}

\Cref{tab:percentages_gurobi_cplex} answers the second question.
\oldtext{Therefore, i}In the first row, figures above 100\% mean Gurobi solved more runs than CPLEX and, in the second row, figures below 100\% mean Gurobi spent less time than CPLEX.
Gurobi have better results for all formulations except the {\modelBecker} formulation in which the results are very similar (only slightly worse).
The choice of Gurobi as solver improve the results for some formulations more than others but, in general, the formulations which solve less instances are the most benefited.
Therefore, we consider Gurobi a fair choice for the rest of the paper

\section{Comparison between formulations}
\label{sec:results_comparing_other_formulations}

The goal of this section is to provide empirical evidence for the choice of one formulation over other, and to identify the impact of allowing rotation over all formulations.
Given the number of considered formulations, we use \Cref{tab:easy18} to filter the considered formulations further.

\begin{table}[h]
  \center
  \caption{Filtering formulations with EASY18 dataset.}
  \setlength\doublerulesep{0.05\baselineskip}
  \begin{tabular}{lrrrrrrrrrr}
    \hline\hline
    & \multicolumn{5}{c}{Fixed} & \multicolumn{5}{c}{Rotation} \\
    \cmidrule(lr){2-6}\cmidrule(lr){7-11}
    Method & \#o & \(g_{lb}\) & \(t_s\) & \(g_{ub}\) & \#f & \#o & \(g_{lb}\) & \(t_s\) & \(g_{ub}\) & \#f \\
    {\modelBCE} & 2 & 7.00 & 3341 & 7.31 & 0 & -- & -- & -- & -- & -- \\
    {\modelBecker} & 18 & 0.00 & \(>1\) & 1.74 & 0 & 18 & 0.00 & \(>1\) & 0.63 & 0 \\
    {\modelFMT} & 13 & 27.78 & 1336 & 2.48 & 4 & 10 & 44.44 & 1723 & 0.71 & 7 \\
    {\modelGrid} & 10 & 33.62 & 1671 & 3.85 & 4 & 3 & 78.23 & 3002 & 3.22 & 9 \\
    {\modelHierarchical} & 16 & 0.08 & 750 & 7.31 & 0 & 14 & 0.31 & 1082 & 3.32 & 0 \\
    {\modelImplicit} & 10 & 0.33 & 1684 & 7.31 & 0 & 9 & 0.45 & 1885 & 3.32 & 0 \\
    {\modelOrigami} & 16 & 0.07 & 685 & 7.31 & 0 & 12 & 0.43 & 1297 & 3.32 & 0 \\\hline\hline
  \end{tabular}
  \legend{
The explanation of these columns follows:
\#o -- number of runs finished by optimality;
\(g_{lb}\) -- the average percentage gap between the best lower bound found and the best known lower bound (if the run finishes without a solution, as is the case of memory exhaustion, we assume a trivial empty solution was returned);
\(t_s\) -- the average total time spent by a run in seconds (both timeout and memory exhaustion count as one hour);
\(g_{ub}\) -- the average percentage gap between the continuous relaxation and the best known lower bound;
\#f -- the number of runs finished by timeout or memory exhaustion during the root node relaxation phase (these are excluded from \(g_{ub}\)).
Source: the author.
  }
  \label{tab:easy18}
\end{table}

\begin{table}[h]
  \center
  \caption{Solving datasets CU and CW}
  \setlength\doublerulesep{0.05\baselineskip}
  \begin{tabular}{lrrrrrrrr}%rrrrrrrr}
    \hline\hline
    & \multicolumn{8}{c}{CU} \\
    \cmidrule(lr){2-9}
    & \multicolumn{4}{c}{Fixed} & \multicolumn{4}{c}{Rotation}\\
    \cmidrule(lr){2-5}\cmidrule(lr){6-9}
    Alg. & \#o & \(g_{lb}\) & \(t_s\) & \(g_{ub}\) & \#o & \(g_{lb}\) & \(t_s\) & \(g_{ub}\) \\
    \cmidrule(lr){1-1}\cmidrule(lr){2-5}\cmidrule(lr){6-9}
    {\modelBecker} & 10 & 9.09 & 425 & 0.21 & 9 & 18.18 & 716 & 0.06 \\
    {\modelHierarchical} & 3 & 0.54 & 2928 & 1.45 & 0 & 0.68 & 3600 & 0.57 \\
    {\modelImplicit} & 0 & 0.80 & 3600 & 1.45 & 0 & 0.88 & 3600 & 0.57 \\
    {\modelOrigami} & 3 & 0.78 & 3021 & 1.45 & 2 & 0.97 & 3400 & 0.57 \\
    \cmidrule(lr){1-1}\cmidrule(lr){2-5}\cmidrule(lr){6-9}
    & \multicolumn{8}{c}{CW}\\
    \cmidrule(lr){2-9}
    & \multicolumn{4}{c}{Fixed} & \multicolumn{4}{c}{Rotation}\\
    \cmidrule(lr){1-1}\cmidrule(lr){2-5}\cmidrule(lr){6-9}
    {\modelBecker} & 11 & 0.00 & 15 & 1.24 & 10 & 0.00 & 496 & 1.72 \\
    {\modelHierarchical} & 5 & 0.00 & 2560 & 11.13 & 3 & 0.01 & 3052 & 5.26 \\
    {\modelImplicit} & 0 & 0.89 & 3600 & 11.13 & 0 & 0.51 & 3600 & 5.26 \\
    {\modelOrigami} & 5 & 0.00 & 2602 & 11.13 & 2 & 0.80 & 3259 & 5.26 \\\hline\hline
  \end{tabular}
  \legend{The columns are the same as of~\cref{tab:easy18} except \#f is ommited because no run was interrupted in the middle of solving the root node. Source: the author.}
  \label{tab:cu_cw}
\end{table}

\Cref{tab:easy18} shows that, for the EASY18 dataset, {\modelBecker} dominates all other formulations.
The {\modelGrid} has the largest average lower bound gap.
The model size often prevents its runs from finishing solving the root node relaxation.
The same problem is also seen in {\modelFMT} runs but to a smaller extent.
{\modelBCE} solves the least instances, its lower bound gap is smaller than {\modelFMT} and {\modelGrid} but considerably above the rest of the instances.
{\modelHierarchical} and {\modelOrigami} solve most instances and have very small lower bound gaps.
Finally, {\modelImplicit} solves an amount of instances comparable to {\modelFMT} and {\modelGrid} but, different from them, the root node relaxation is always solved and a good primal solution too.

Considering these results, the authors chose to remove {\modelBCE}, {\modelGrid}, and {\modelFMT} from further comparison.
The rationale for these choices follows: {\modelBCE} solves very few instances leading to a great increase in experiment times; the model size of {\modelGrid} leads to memory problems, especially for runs allowing rotation; and {\modelFMT} is similar to {\modelBecker} but without some additional enhancements.

In \Cref{tab:cu_cw}, we see two distinct behaviors emerge.
The {\modelBecker} (pseudo-polynomial) starts to present a behavior similar to {\modelFMT}: either solving the instances faster than the other formulations, or failing to solve the root node relaxation at all\footnote{The table ommits it but {\modelBecker} fails to solve the root node relaxation one time for CU/Fixed and two times for CU/Rotation.}.
The other three formulations have difficulty to prove optimality, however they always solve the root node relaxation and provide primal solutions of good quality.
The \(g_{ub}\) column indicates that {\modelHierarchical}, {\modelImplicit}, and {\modelOrigami} have the same average upper bound gap.
The reason for this similarity is that the three formulations, while distinct, make use of the same additional constraints to tighten the upper bound to a precomputed value.
In all three formulations, these constraints impose a tighter bound than the one imposed by the remainder of the formulation, leading to this similarity.
The problem becomes harder for all formulations if rotation is allowed.
The values in the \(g_{ub}\) column for {\modelHierarchical}, {\modelImplicit}, and {\modelOrigami} reduce when rotation is allowed, however this happens only because their upper bounds stay the same while the best known solution increases in value.

\begin{table}[h]
  \center
  \caption{Solving datasets FMT59 and APT}
  \setlength\doublerulesep{0.05\baselineskip}
  \begin{tabular}{lrrrrrrrrrr} %rrrrr}
    \hline\hline
    & \multicolumn{10}{c}{FMT59}\\
    \cmidrule(lr){2-11}
    & \multicolumn{5}{c}{Fixed} & \multicolumn{5}{c}{Rotation} \\
    \cmidrule(lr){2-6}\cmidrule(lr){7-11}
    Method & \#o & \(g_{lb}\) & \(t_s\) & \(g_{ub}\) & \#f & \#o & \(g_{lb}\) & \(t_s\) & \(g_{ub}\) & \#f \\
    \cmidrule(lr){1-1}\cmidrule(lr){2-6}\cmidrule(lr){7-11}
    {\modelBecker} & 57 & 1.69 & 183 & 1.75 & 1 & 56 & 1.05 & 233 & 3.28 & 1 \\
    {\modelHierarchical} & 27 & 1.00 & 2387 & 4.89 & 0 & 20 & -1.16 & 2657 & 4.66 & 0 \\
    {\modelImplicit} & 10 & 1.40 & 3015 & 4.89 & 0 & 9 & -1.04 & 3077 & 4.66 & 0 \\
    {\modelOrigami} & 25 & 1.39 & 2328 & 4.89 & 0 & 13 & -0.74 & 2837 & 4.66 & 0 \\
    \cmidrule(lr){1-1}\cmidrule(lr){2-6}\cmidrule(lr){7-11}
    & \multicolumn{10}{c}{APT} \\
    \cmidrule(lr){2-11}
    & \multicolumn{5}{c}{Fixed} & \multicolumn{5}{c}{Rotation} \\
    \cmidrule(lr){1-1}\cmidrule(lr){2-6}\cmidrule(lr){7-11}
    {\modelBecker} & 0 & 100.00 & 3600 & -- & 20 & -- & -- & -- & -- & -- \\
    {\modelHierarchical} & 0 & 11.32 & 3601 & 1.86 & 0 & -- & -- & -- & -- & -- \\
    {\modelImplicit} & 0 & 3.10 & 3600 & 1.86 & 0 & -- & -- & -- & -- & -- \\
    {\modelOrigami} & 0 & 90.39 & 3509 & 1.90 & 9 & -- & -- & -- & -- & -- \\\hline\hline
  \end{tabular}
  \legend{The columns are the same as of~\cref{tab:easy18}.}
  \label{tab:fmt59_apt}
\end{table}

\Cref{tab:fmt59_apt} corroborates the findings of~\Cref{tab:cu_cw}.
{\modelBecker} solves more FMT59 instances, but ends up with a larger \(g_{lb}\) than the other formulations because of the poor solution quality in the few unsolved instances.
For the FMT59 instances, {\modelHierarchical} has the lowest~\(g_{lb}\) but, for the APT instances {\modelImplicit} surpasses it.
The {\modelBecker} is unable to solve the root node relaxation for any of the APT instances during the one hour time limit.
The column~FMT59/Rotation/\(g_{lb}\) has negative values because, as mentioned in~\Cref{sec:outine_experiments_other_formulations}, we use the known optima from fixed orientation for this particular dataset.

