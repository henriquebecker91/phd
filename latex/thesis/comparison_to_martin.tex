\chapter{\protect\newtext{Comparison to other formulations of the literature}}
\label{sec:martin_chapter}

This chapter compares the proposed formulation (BBA) to another five formulations of the recent literature besides its immediate predecessor (FMT).
A concise review of these other formulations is given in~\cref{sec:other_formulations}.
Differently from BBA and FMT, the employed implementation of these formulations was written in C++ for the CPLEX solver and not by the author of this thesis.
To control differences between the implementations, the design of the experiments is different from the other chapters: the implementations are used only to generate and save the models into files (not to solve the models), and both CPLEX and Gurobi are called from the command line to solve each of these saved models.
To avoid any doubts about the specific experiment setup and design, the same is exhaustively described in~\cref{sec:setup_other_formulations} and~\cref{sec:outine_experiments_other_formulations}.
Besides the comparison between the formulations in~\cref{sec:results_comparing_other_formulations}, a comparison between solvers is also presented (\cref{sec:results_comparing_solvers}), which allows us to dispel any doubts about the choice of solver favouring one formulation over another.

Another relevant distinction is that these other formulation are, in general, more compact and easier to implement in a GAMS-like framework.
As it was seen in~\cref{sec:comparison}, the time spent by FMT/BBA in the cut-and-plate enumeration is often negligible (less than 0.2\% for the FMT59 dataset), however implementing this enumeration correctly and efficiently is no trivial task.

\section{Concise review of the newly considered formulations}
\label{sec:other_formulations}

For the sake of explanation, the author chose to aggregate some of the formulations in the same paragraph when they share similar modelling strategies.
The author seeks to highlight how the interpretation of solutions can lead to very different formulations.

\emph{The {\modelBCE} formulation}, proposed for the Guillotine Strip Packing Problem in~\citet{messaoud:2008} and adapted for the {\myproblem} in~\citet{martin:2020}, is based on a theorem that characterizes guillotine patterns and uses coordinates at which items may be located.
The theorem states that a pattern is of guillotine type if, and only if, for any region (i.e., sub-rectangle) of the object, at least one of the following conditions is satisfied:
(i) this region contains only a single item;
(ii) the segments of the piece length in this region on the x-axis consist of at least two disjoint intervals;
and, (iii) the segments of the piece width in this region on the y-axis consist of at least two disjoint intervals.
The formulation is compact in the numbers of variables and constraints with \(O(n^4)\) for the GSPP, where \(n\) is the number of pieces to be packed.
This formulation seems to recall the interval-graph approach of \citet{fekete:1997} for the non-guillotine Orthogonal Packing Problem.

\emph{The {\modelGrid} formulation}, proposed in~\citet{martin:2020}, assumes that each solution can be represented by a sequence of horizontal and vertical guillotine cuts over a two-dimensional grid interpretation of object \(L \times W\).
It was inspired by a formulation for the non-guillotine {\myproblem} from~\citet{beasley:1985:nonguillotine}.
In a {\modelGrid} model, a binary variable \(x_{kij}\) represents the allocation of the left-bottom corner of an piece type~\(k \in \{1,\ldots,m\}\) to a point \((i,j)\) on the object, \(0 \leq i \leq L-l_k\), \(0 \leq j \leq W-w_k\).
Taking into consideration the constraints from~\citet{beasley:1985:nonguillotine}, it ensures a constrained pattern and avoids the overlap between any pair of allocated/cut pieces, which is related to a maximum clique problem.
Then it satisfies the guillotine cutting with binary variables for horizontal cuts \(h_{ii\prime j}\), \(0 \leq i < i\prime \leq L\), \(0 \leq j \leq W\), vertical cuts \(v_{ijj\prime}\), \(0 \leq i \leq L\), \(0 \leq j < j\prime \leq W\), and enabled rectangles \(p_{i_1 i_2 j_1 j_2}\), \(0 \leq i_1 < i_2 \leq L\), \(0 \leq j_1 < j_2 \leq W\).
The main concepts involve associating:
(i) the variables \(x_{kij}\), \(h_{ijj\prime}\) and \(v_{ii\prime j}\) by prohibiting horizontal and vertical cuts on allocated pieces and imposing the allocation of the pieces on cut corners;
(ii) the variables \(h_{ii\prime j}\), \(v_{ijj\prime}\) and \(p_{i_1 i_2 j_1 j_2}\) by allowing only horizontal and vertical edge-to-edge cuts in enabled rectangles.
The formulation is pseudo-polynomial in the numbers of variables and constraints with \(O(mLW+L^2W^2)\).
As expected, one can reduce the number of variables and constraints by using the discretization of normal sets or related ones \citet{herz:1972,cw:1977}.
%Part of these modeling strategies was explored in the context of an object with several defects in~\cite{martin:2020:ijpr,martin:2021:ijpr}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Martin et al. (2020) - bottom-up and top-down
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\emph{The {\modelHierarchical} and {\modelImplicit} formulations}, proposed in~\citet{martin:2020:bottom}, are inspired in the bottom-up strategy of successive horizontal and vertical builds of the pieces.
A build envelops two small rectangles to generate a larger rectangle.
For instance, as introduced in~\citet{wang:1983}, the horizontal build of pieces \(l_1 \times w_1\) and \(l_2 \times w_2\) provides a larger rectangle of size \((l_1+l_2)\times \max\{w_1, w_2\}\), and the vertical build provides a larger rectangle of size \(\max\{l_1, _2\} \times (w_1+w_2)\).
Defining an {\modelHierarchical} or {\modelImplicit} model, it requires to previously determine an upper bound \(\bar{n}\) to the maximum number of builds on object \(L \times W\) (e.g., \(\bar{n}=\sum_{i \in I} b_i\)).
The {\modelHierarchical} formulation is pseudo-polynomial as its definition requires an explicit binary tree structure, which is generated by a procedure that considers upper bound \(\bar{n}\) as an input.
This binary tree structure is represented by a set of triplets \((j,j^-,j^+)\), where \(j^-$ and $j^+\) are the left and right child nodes of node \(j\), respectively; the root node \(j=1\) represents the object (i.e., the solution).
Its main concepts involve ensuring:
(i) each node \(j\) of the binary tree structure can represent either a copy of an item type \(i \in I\) (binary variable \(z_{ji}\)), an horizontal build (binary variable \(x_{jh}\)), a vertical build (variable \(x_{jv}\)), or it is not necessary in the solution;
(ii) the solution represents a guillotine pattern (i.e., a virtual binary tree) by linking the variables \(x_{jo}\), \(o \in \{h,v\}\), of each parent node \(j\) with the variables of its child nodes \(j^-\) and \(j^+\); and,
(iii) the variables \(L_j\) and \(W_j\) are considered to represent, respectively, the length and width of a node \(j\) according to the previous definition of horizontal and vertical builds, over variables \(z_{ji}\) and \(x_{jo}\).
The {\modelImplicit} formulation, however, is compact as it considers the set of binary variables \(y_{jk}\), \(j,k \in \{1,\ldots,\bar{n}-1\}\), \(j<k\), for representing implicitly the binary tree structure.
The {\modelHierarchical} and {\modelImplicit} formulations were first proposed as integer non-linear programs, and then they were linearized through the use of disjunctive inequalities of big-M type.

\emph{The {\modelOrigami} formulation}, proposed in~\citet{martin:2020:top}, is inspired in the top-down strategy of successive cuts on the original and residual objects towards the items.
It makes use of the binary tree structure initially proposed for the {\modelHierarchical} formulation.
As a consequence, it presumes the same constraints for representing a guillotine pattern (i.e., a virtual binary tree) by linking the variables \(x_{jo}\), \(o \in \{h,v\}\), of each parent node \(j\) with the variables of its child nodes \(j^-\) and \(j^+\).
However, its geometric constraints are non-trivial.
Since variables \(L_j\) and \(W_j\) are no longer in the formulation, the sizes of the residual objects (i.e., nodes of the binary tree structure) are defined according to the decisions taken in the previous residual objects.
Alternatively stated, the decisions of each node~\(j\) take into consideration the previous decisions of all its ancestral nodes up to the root node through disjunctive inequalities of big-M type.

\section{Experiments setup}
\label{sec:setup_other_formulations}

Every experiment in this section used the following setup.
The CPU was an AMD\textsuperscript{\textregistered} Ryzen\textsuperscript{TM} 9 3900X 12-Core Processor %(3.8GHz, cache: L1 -- 768KiB, L2 -- 6 MiB, L3 -- 64 MiB)
and 32GiB of RAM were available. %(2 x Crucial Ballistix Sport Red DDR4 16GB 2.4GHz)
The operating system was Ubuntu 20.04 LTS (Linux 5.4.0).
Two kernel parameters had non-default values: \texttt{overcommit_memory = 2} and \texttt{overcommit_ratio = 95}.
Hyper-Threading was disabled.
Each run executed on a single thread, and no runs executed simultaneously.
The computer did not run any other CPU bound task during the experiments.

The models for the {\modelBecker} and {\modelFMT} formulations were built using the Julia language and the Gurobi solver.
The models for the {\modelBCE}, {\modelGrid}, {\modelHierarchical}, {\modelImplicit}, and {\modelOrigami} formulations were built using C++ and the CPLEX solver.
To homogenize the experiments, these implementations were used only to build the models and then save them to MPS files.
Each selected combination of formulation, rotation configuration, and instance originated a single MPS file.
A Julia script then executed each MPS file in four different configurations: CPLEX/LP, CPLEX/MILP, Gurobi/LP, and Gurobi/MILP.

The implementation of {\modelBecker} and {\modelFMT} formulations is available at an online repository\footnote{See~\url{https://github.com/henriquebecker91/GuillotineModels.jl/tree/0.5.0}}.
The scripts for (i) saving the {\modelBecker} and {\modelFMT} models as MPS and (ii) solving all MPS files are also availables\footnote{See~\url{https://github.com/henriquebecker91/phd/tree/BMC-1}}.
The implementations of all the other formulations, as well as the script for generating the MPS files, are available upon request to Martin Pereira Martin\footnote{The ORCID of Martin Pereira Martin is \href{https://orcid.org/0000-0002-6722-7571}{0000-0002-6722-7571}.
He is the main author of \citet{martin:2020}, \citet{martin:2020:bottom}, and \citet{martin:2020:top}.} who graciously let the author borrow his implementations for the purpose of this comparison. %at~\url{https://github.com/mateuspmartin/g2slopp/tree/BMC-1} (CHECK WITH MARTIN IF WE ARE GONNA UN-PRIVATE IT NOW).
The same version of the compilers and solvers was used for the MPS generation and the MPS solving phases.Those are: Julia 1.5.3, g++ 9.3.0, CPLEX 20.1, and Gurobi 9.1.1.
%At least for the solvers, these were the latest versions available.

In both CPLEX and Gurobi some non-default configurations were used.
The solvers were configured to:
employ a single thread;
use a specified seed (\texttt{CPX_PARAM_RANDOMSEED}, in CPLEX, and \texttt{Seed}, in Gurobi, were set to one);
employ an integer tolerance adequate for the instances; avoid finishing with suboptimal solutions for the selected datasets (\texttt{CPX_PARAM_EPGAP}, in CPLEX, and \texttt{MIPGap}, in Gurobi, were set to \(10^{-6}\));
and respect an one hour time-limit (\texttt{CPX_PARAM_TILIM}, in CPLEX, and \texttt{TimeLimit}, in Gurobi, were set to 3600). For a more graceful handling of memory exhaustion, set CPLEX parameter \texttt{CPXPARAM_MIP_Limits_TreeMemory} is set to 28672 (Gurobi does not seem to provide a similar parameter).
Only when solving the {\modelFMT} and {\modelBecker} formulations, the solver employs the barrier method for solving the LP and for solving the root node relaxation (\texttt{CPXPARAM_LPMethod} and \texttt{CPXPARAM_MIP_Strategy_StartAlgorithm}, in CPLEX, were both set to 4, and \texttt{Method}, in Gurobi, was set to 2).

\section{Outline of the experiments}
\label{sec:outine_experiments_other_formulations}

A short description of the instance datasets used in this section follows.
More details about each dataset can be found in the Appendix.

\begin{description}
	\item [CU/CW] Datasets introduced by~\citet{fayard:1998}. Their names stand for Constrained (demand) and Unweighted/Weighted. They totalise 22 instances: CU1--11 and CW1--11.
	% APT: 10.1016/S0305-0548(00)00095-2
	\item [APT] Dataset introduced by~\citet{alvarez:2002:tabu}. The whole dataset consists of 40 instances (APT10--49), however, only the second half (APT30--49) is employed here, because the first half is for the unconstrained demand variant. The APT30--39 are unweighted and APT40--49 are weighted.
	\item [FMT59] Group of instances assembled by~\cite{furini:2016} with instance subsets from previous datasets. Already employed in previous chapters.
	\item [Easy18] A subset of FMT59 defined by the author for this section. Its purpose is to reduce the number of runs needed before discarding a formulation from further consideration. The dataset contains: cgcut1--3, gcut1--12, OF1--2, and wang20.
\end{description}

The author selected these datasets because the prior work already employed them.
For the CU, CW, and APT datasets, with and without rotation, the best known lower bounds from~\citet{velasco:2019} are used.
For the FMT59 dataset, without rotation, \citet{furini:2016} presents every optimal value\footnote{There is only one typo: the optimal value of the okp2 instance is 22502, not 22503.}, but there is no comprehensive source on the best known values for this dataset when rotation is allowed.

Each run can be uniquely identified by a combination of instance, formulation, rotation configuration (allow rotation or not), solve mode (MILP or LP), and solver (CPLEX or Gurobi).
The first three characteristics determine an MPS file; the last two determine four distinct runs over the same MPS file.

The whole set of runs consists of:
\begin{enumerate}
\item The Easy18 instances combined with each of the seven considered formulations and both rotation configurations, except by the BCE formulation with rotation enabled, which was not implemented.
\item The CU, CW, and FMT59 instances combined with the {\modelBecker}, {\modelOrigami}, hierachical, and {\modelImplicit} formulations and both rotation configurations.
\item The APT instances combined with the four formulations mentioned above but only with rotation disabled. No runs found optimality with rotation disabled and, therefore, the author decided to not spend computational effort in the rotation-enabled counterparts. % TODO: check with Martin if we should run the rotation ones for APT.
\end{enumerate}

\section{Comparison between CPLEX and Gurobi}
\label{sec:results_comparing_solvers}

This section aims to answer two questions: (i) is one of the solvers superior in this context? (ii) does a choice of solver benefit a specific formulation?

\Cref{tab:cplex_vs_gurobi} answers the first question by revealing a small but consistent advantage for the Gurobi solver.
Nevertheless, Gurobi does not completely dominate CPLEX, as each solver had some instances only solved by it.

\begin{table}[h]
  \center
  \caption{Comparison amongst CPLEX and Gurobi results.}
  \setlength\doublerulesep{0.05\baselineskip}
  \begin{tabular}{lcrrrrrr}
    \hline\hline
    \textbf{Solver} & \textbf{Type} & \textbf{\#opt} & \textbf{\#u. opt} & \textbf{\#best} & \textbf{\#c. best} & \textbf{Avg. T (s)} & \textbf{Avg. S. T. (s)} \\\cmidrule(lr){1-2}\cmidrule(lr){3-8}
     CPLEX & MILP & 288 & 12 &  96 & 16 & 2435.86 & 455.21 \\
    Gurobi & MILP & 302 & 26 & 218 & 63 & 2339.84 & 353.62 \\
     CPLEX & LP  & 704 &  4 & 194 &  6 &  379.17 &  40.62 \\
    Gurobi & LP  & 720 & 20 & 530 & 24 &  297.79 &  31.78 \\\hline\hline
  \end{tabular}
  \legend{
\justifying
The meaning of each column follow:
\emph{\#opt} -- number of runs finished by optimality;
\emph{\#u. opt} -- number of optimal runs unique to the respective solver (i.e., other solver did not reach optimality);
\emph{\#best} -- number of optimal runs in which the respective solver finished before the other solver (counting the ones not finished by the other solver);
\emph{\#c. best} -- number of clean best times, i.e., optimal runs that took at least one minute for the respective solver and either were not solved by the other solver or it took double the time to solve;
\emph{Avg. T. (s)} -- mean run time in seconds (runs ended by timeout or memory exhaustion are counted as taking one hour);
\emph{Avg. S. T. (s)} -- mean run time of solved runs in seconds.
  }
  \label{tab:cplex_vs_gurobi}
\end{table}

\begin{table}[h]
  \center
  \caption{Comparison amongst CPLEX and Gurobi results by formulation.}
  \setlength\doublerulesep{0.05\baselineskip}
  \begin{tabular}{lrrrrrrr}
    \hline\hline
    \textbf{Measure} & \textbf{\modelBCE} & \textbf{\modelBecker} & \textbf{\modelFMT} & \textbf{\modelGrid} & \textbf{\modelHierarchical} & \textbf{\modelImplicit} & \textbf{\modelOrigami} \\\hline
    Optimal & 105.88 &  99.31 & 131.57 & 150.00 & 100.00 & 100.00 & 101.24 \\
    T. Time &  85.45 & 101.75 &  74.71 &  58.61 &  45.09 &  27.68 &  67.60 \\\hline\hline
  \end{tabular}
  \legend{
\justifying
Percentage of solved runs and total time spent by Gurobi in relation to CPLEX, broken down by formulation, for all MILP runs. Runs ended by time or memory limit are counted as taking one hour. Source: the author.
}
  \label{tab:percentages_gurobi_cplex}
\end{table}

\Cref{tab:percentages_gurobi_cplex} answers the second question.
\oldtext{Therefore, i}In the first row, figures above 100\% mean Gurobi solved more runs than CPLEX and, in the second row, figures below 100\% mean Gurobi spent less time than CPLEX.
Gurobi has better results for all formulations except the {\modelBecker} formulation, in which the results are very similar (only slightly worse).
The choice of Gurobi as a solver improves the results for some formulations more than others, but, in general, the formulations which solve fewer instances are the most beneficial.
Therefore, the author considers Gurobi a fair choice for the rest of the paper

\section{Comparison between formulations}
\label{sec:results_comparing_other_formulations}

This section aims to provide empirical evidence for the choice of one formulation over another and to identify the impact of allowing rotation over all formulations.
Given the number of considered formulations, \Cref{tab:easy18} filters the considered formulations further.

\begin{table}[h]
  \center
  \caption{Filtering formulations with EASY18 dataset.}
  \setlength\doublerulesep{0.05\baselineskip}
  \begin{tabular}{lrrrrrrrrrr}
    \hline\hline
    & \multicolumn{5}{c}{Fixed} & \multicolumn{5}{c}{Rotation} \\
    \cmidrule(lr){2-6}\cmidrule(lr){7-11}
    Method & \#opt & \(g_{lb}\) & Avg. T. & \(g_{ub}\) & \#f & \#opt & \(g_{lb}\) & Avg. T. & \(g_{ub}\) & \#f \\
    \cmidrule(lr){2-6}\cmidrule(lr){7-11}
    {\modelBCE} & 2 & 7.00 & 3341 & 7.31 & 0 & -- & -- & -- & -- & -- \\
    {\modelBecker} & 18 & 0.00 & \(<1\) & 1.74 & 0 & 18 & 0.00 & \(<1\) & 0.63 & 0 \\
    {\modelFMT} & 13 & 27.78 & 1336 & 2.48 & 4 & 10 & 44.44 & 1723 & 0.71 & 7 \\
    {\modelGrid} & 10 & 33.62 & 1671 & 3.85 & 4 & 3 & 78.23 & 3002 & 3.22 & 9 \\
    {\modelHierarchical} & 16 & 0.08 & 750 & 7.31 & 0 & 14 & 0.31 & 1082 & 3.32 & 0 \\
    {\modelImplicit} & 10 & 0.33 & 1684 & 7.31 & 0 & 9 & 0.45 & 1885 & 3.32 & 0 \\
    {\modelOrigami} & 16 & 0.07 & 685 & 7.31 & 0 & 12 & 0.43 & 1297 & 3.32 & 0 \\\hline\hline
  \end{tabular}
  \legend{
\justifying
The explanation of these columns follows:
\#opt -- the number of runs finished by optimality;
\(g_{lb}\) -- the average percentage gap between the best lower bound found and the best known lower bound (if the run finishes without a solution, as is the case of memory exhaustion, it is assumed that a trivial empty solution was returned);
Avg. T. -- the average total time spent by a run in seconds (both timeout and memory exhaustion count as one hour);
\(g_{ub}\) -- the average percentage gap between the continuous relaxation and the best known lower bound;
\#f -- the number of runs finished by timeout or memory exhaustion during the root node relaxation phase (these are excluded from \(g_{ub}\)).
Source: the author.
  }
  \label{tab:easy18}
\end{table}

\begin{table}[h]
  \center
  \caption{Solving datasets CU and CW}
  \setlength\doublerulesep{0.05\baselineskip}
  \begin{tabular}{lrrrrrrrr}%rrrrrrrr}
    \hline\hline
    & \multicolumn{8}{c}{CU} \\
    \cmidrule(lr){2-9}
    & \multicolumn{4}{c}{Fixed} & \multicolumn{4}{c}{Rotation}\\
    \cmidrule(lr){2-5}\cmidrule(lr){6-9}
    Alg. & \#opt & \(g_{lb}\) & Avg. T. & \(g_{ub}\) & \#opt & \(g_{lb}\) & Avg. T. & \(g_{ub}\) \\
    \cmidrule(lr){1-1}\cmidrule(lr){2-5}\cmidrule(lr){6-9}
    {\modelBecker} & 10 & 9.09 & 425 & 0.21 & 9 & 18.18 & 716 & 0.06 \\
    {\modelHierarchical} & 3 & 0.54 & 2928 & 1.45 & 0 & 0.68 & 3600 & 0.57 \\
    {\modelImplicit} & 0 & 0.80 & 3600 & 1.45 & 0 & 0.88 & 3600 & 0.57 \\
    {\modelOrigami} & 3 & 0.78 & 3021 & 1.45 & 2 & 0.97 & 3400 & 0.57 \\
    \cmidrule(lr){1-1}\cmidrule(lr){2-5}\cmidrule(lr){6-9}
    & \multicolumn{8}{c}{CW}\\
    \cmidrule(lr){2-9}
    & \multicolumn{4}{c}{Fixed} & \multicolumn{4}{c}{Rotation}\\
    \cmidrule(lr){1-1}\cmidrule(lr){2-5}\cmidrule(lr){6-9}
    {\modelBecker} & 11 & 0.00 & 15 & 1.24 & 10 & 0.00 & 496 & 1.72 \\
    {\modelHierarchical} & 5 & 0.00 & 2560 & 11.13 & 3 & 0.01 & 3052 & 5.26 \\
    {\modelImplicit} & 0 & 0.89 & 3600 & 11.13 & 0 & 0.51 & 3600 & 5.26 \\
    {\modelOrigami} & 5 & 0.00 & 2602 & 11.13 & 2 & 0.80 & 3259 & 5.26 \\\hline\hline
  \end{tabular}
  \legend{
\justifying
The columns are the same as of~\cref{tab:easy18} except \#f is ommited because no run was interrupted in the middle of solving the root node. Source: the author.
}
  \label{tab:cu_cw}
\end{table}

\Cref{tab:easy18} shows that, for the EASY18 dataset, {\modelBecker} dominates all other formulations.
The {\modelGrid} has the largest average lower bound gap.
The model size often prevents its runs from finishing solving the root node relaxation.
The same problem is also seen in {\modelFMT} runs but to a smaller extent.
{\modelBCE} solves the least instances; its lower bound gap is smaller than {\modelFMT} and {\modelGrid} but considerably above the rest of the instances.
{\modelHierarchical} and {\modelOrigami} solve most instances and have very small lower bound gaps.
Finally, {\modelImplicit} solves a number of instances comparable to {\modelFMT} and {\modelGrid} but, different from them, the root node relaxation is always solved, and a good primal solution is delivered.

Considering these results, the authors chose to remove {\modelBCE}, {\modelGrid}, and {\modelFMT} from further comparison.
The rationale for these choices follows: {\modelBCE} solves very few instances leading to a great increase in experiment times; the model size of {\modelGrid} leads to memory problems, especially for runs allowing rotation; and {\modelFMT} is similar to {\modelBecker} but without some additional enhancements.

In \Cref{tab:cu_cw}, it can be seen that two distinct behaviours emerge.
The {\modelBecker} (pseudo-polynomial) starts to present a behaviour similar to {\modelFMT}: either solving the instances faster than the other formulations, or failing to solve the root node relaxation at all\footnote{The table omits it but {\modelBecker} fails to solve the root node relaxation one time for CU/Fixed and two times for CU/Rotation.}.
The other three formulations have difficulty proving optimality; however, they always solve the root node relaxation and provide primal solutions of good quality.
The \(g_{ub}\) column indicates that {\modelHierarchical}, {\modelImplicit}, and {\modelOrigami} have the same average upper bound gap.
The reason for this similarity is that the three formulations, while distinct, use the same additional constraints to tighten the upper bound to a precomputed value.
In all three formulations, these constraints impose a tighter bound than the one imposed by the remainder of the formulation, leading to this similarity.
The problem becomes harder for all formulations if rotation is allowed.
The values in the \(g_{ub}\) column for {\modelHierarchical}, {\modelImplicit}, and {\modelOrigami} reduce when rotation is allowed; however, this only happens because their upper bounds stay the same while the best known solution increases in value.

\begin{table}[h]
  \center
  \caption{Solving datasets FMT59 and APT}
  \setlength\doublerulesep{0.05\baselineskip}
  \begin{tabular}{lrrrrrrrrrr} %rrrrr}
    \hline\hline
    & \multicolumn{10}{c}{FMT59}\\
    \cmidrule(lr){2-11}
    & \multicolumn{5}{c}{Fixed} & \multicolumn{5}{c}{Rotation} \\
    \cmidrule(lr){2-6}\cmidrule(lr){7-11}
    Method & \#opt & \(g_{lb}\) & Avg. T. & \(g_{ub}\) & \#f & \#opt & \(g_{lb}\) & Avg. T. & \(g_{ub}\) & \#f \\
    \cmidrule(lr){1-1}\cmidrule(lr){2-6}\cmidrule(lr){7-11}
    {\modelBecker} & 57 & 1.69 & 183 & 1.75 & 1 & 56 & 1.05 & 233 & 3.28 & 1 \\
    {\modelHierarchical} & 27 & 1.00 & 2387 & 4.89 & 0 & 20 & -1.16 & 2657 & 4.66 & 0 \\
    {\modelImplicit} & 10 & 1.40 & 3015 & 4.89 & 0 & 9 & -1.04 & 3077 & 4.66 & 0 \\
    {\modelOrigami} & 25 & 1.39 & 2328 & 4.89 & 0 & 13 & -0.74 & 2837 & 4.66 & 0 \\
    \cmidrule(lr){1-1}\cmidrule(lr){2-6}\cmidrule(lr){7-11}
    & \multicolumn{10}{c}{APT} \\
    \cmidrule(lr){2-11}
    & \multicolumn{5}{c}{Fixed} & \multicolumn{5}{c}{Rotation} \\
    \cmidrule(lr){1-1}\cmidrule(lr){2-6}\cmidrule(lr){7-11}
    {\modelBecker} & 0 & 100.00 & 3600 & -- & 20 & -- & -- & -- & -- & -- \\
    {\modelHierarchical} & 0 & 11.32 & 3601 & 1.86 & 0 & -- & -- & -- & -- & -- \\
    {\modelImplicit} & 0 & 3.10 & 3600 & 1.86 & 0 & -- & -- & -- & -- & -- \\
    {\modelOrigami} & 0 & 90.39 & 3509 & 1.90 & 9 & -- & -- & -- & -- & -- \\\hline\hline
  \end{tabular}
  \legend{The columns are the same as of~\cref{tab:easy18}.}
  \label{tab:fmt59_apt}
\end{table}

\Cref{tab:fmt59_apt} corroborates the findings of~\Cref{tab:cu_cw}.
{\modelBecker} solves more FMT59 instances but ends up with a larger \(g_{lb}\) than the other formulations because of the poor solution quality in the few unsolved instances.
For the FMT59 instances, {\modelHierarchical} has the lowest~\(g_{lb}\) but, for the APT instances {\modelImplicit} surpasses it.
The {\modelBecker} cannot solve the root node relaxation for any APT instances during the one-hour time limit.
The column~FMT59/Rotation/\(g_{lb}\) has negative values because, as mentioned in~\Cref{sec:outine_experiments_other_formulations}, the author chose to use the known optima from fixed orientation for this particular dataset.

